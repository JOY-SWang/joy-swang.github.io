---
title: "Mlevlm: Improve multi-level progressive capabilities based on multimodal large language model for medical visual question answering."
collection: publications
category: conferences
permalink: /publication/Mlevlm
excerpt: 'This paper is about the number 3. The number 4 is left for future work.'
date: 2024-07
venue: 'ACL2024'
paperurl: 'https://aclanthology.org/2024.findings-acl.296.pdf'
citation: 'Your Name, You. (2015). &quot;Paper Title Number 3.&quot; <i>Journal 1</i>. 1(3).'
---

We propose MLeVLM, a Multi-level Visual Language Model for **Medical Visual Question Answering** focusing on recognition, details, diagnosis, knowledge, and reasoning. We construct a high-quality multi-level dataset (MLe-VQA) and a multi-level feature alignment module, and create a benchmark which MLeVLM outperforms.